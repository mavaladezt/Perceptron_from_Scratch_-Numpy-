{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron for Banknotes/Checks Authentication \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron<br>\n",
    "Perceptron is a supervised learning binary classifier.\n",
    "In order to predict, perceptron first tries to find an hyperplane between the 2 sets of data. If the hyperplane exists the data can be easily classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was obtained from:<br>\n",
    "__Dua, D. and Graff, C. (2019). UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/banknote+authentication). Irvine, CA: University of California, School of Information and Computer Science.__<br>\n",
    "\n",
    "Abstract: Data were extracted from images that were taken for the evaluation of an authentication procedure for banknotes.<br>\n",
    "\n",
    "Features:<br> \n",
    " 1. variance of Wavelet Transformed image (continuous)\n",
    " 2. skewness of Wavelet Transformed image (continuous)\n",
    " 3. curtosis of Wavelet Transformed image (continuous)\n",
    " 4. entropy of image (continuous)\n",
    " 5. class (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1372, 5)\n"
     ]
    }
   ],
   "source": [
    "#Importing the text file\n",
    "data=np.loadtxt('data_banknote_authentication.txt',delimiter=',')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxplot of features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a250cf940>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Boxplot of features:')\n",
    "sns.boxplot(data=data[:,0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since any variable seems to be way to different than the rest, I think I will be ok without normalizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly Generated Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of data used for training 0.706268221574344\n"
     ]
    }
   ],
   "source": [
    "random_column = np.array(np.random.rand(data.shape[0]))  #create random column so I can divide train/test sets\n",
    "data=np.concatenate((data,random_column.reshape(data.shape[0],1)),axis=1)  #add random values column to set\n",
    "train=data[data[:,5]<=.7]  #Aproximately 70% of the data will be used as training data\n",
    "test=data[data[:,5]>.7]    #rest will be testing data\n",
    "print(\"Proportion of data used for training\",train.shape[0]/data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train features and y\n",
    "train=train[:,0:train.shape[1]-1]          #eliminate the random column, we don't need it anymore\n",
    "y_train=train[:,-1]                        #get y from dataset (which is now the lat column)\n",
    "y_train=np.where(y_train==0, -1, y_train)  #replace ceros for -1\n",
    "x_train=train[:,0:train.shape[1]-1]        #eliminating the y column, this is now our feature set\n",
    "\n",
    "#Test features and y. Same as above but with test set\n",
    "test=test[:,0:test.shape[1]-1]\n",
    "y_test=test[:,-1]\n",
    "y_test=np.where(y_test==0, -1, y_test)\n",
    "x_test=test[:,0:test.shape[1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train positives 427.0 \ttrain negatives 542.0\n",
      "test positives 183.0 \ttest negatives 220.0\n"
     ]
    }
   ],
   "source": [
    "#summary of positves and negatives in both datasets\n",
    "print('train positives',np.sum(y_train[y_train==1]),'\\ttrain negatives',-np.sum(y_train[y_train==-1]))\n",
    "print('test positives',np.sum(y_test[y_test==1]),'\\ttest negatives',-np.sum(y_test[y_test==-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_update(x,y,w):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    x : input vector with features\n",
    "    y : labels (-1 or +1)\n",
    "    w : weight vector, same dimensions as x\n",
    "    Output:\n",
    "    w : updated weight vector\n",
    "    \"\"\"\n",
    "    w=w+x*y\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(xs,ys):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    xs : n input vectors of d dimensions (nxd)\n",
    "    ys : n labels (-1 or +1)\n",
    "    Output:\n",
    "    w : final weight vector (1xd)\n",
    "    b : bias term\n",
    "    \"\"\"\n",
    "    n, d = xs.shape     # so we have n input vectors, of d dimensions each\n",
    "    w = np.zeros(d)\n",
    "    b = 0.0\n",
    "    iteration=0         #will keep in max iterations in 100 but if there is an hyperplane it will find it way before\n",
    "    while iteration < 100:\n",
    "        m=0\n",
    "        for i in np.random.permutation(n):   #data has to be randomly loaded to prevent learning order too\n",
    "            if ( ( (xs[i]@w.T)+b ) * ys[i] )<=0:\n",
    "                w=perceptron_update(xs[i],ys[i],w)\n",
    "                b+=ys[i]\n",
    "                m+=1\n",
    "        iteration += 1\n",
    "        if m==0:\n",
    "            break\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will be calculating the weights (vector) and bias and use it to predict y in test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final weight vector and bias\n",
    "weights,bias=perceptron(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_classify(xs,w,b=None):\n",
    "    \"\"\"\n",
    "    Make predictions with a linear classifier\n",
    "    Input:\n",
    "    xs : n input vectors of d dimensions (nxd) [could also be a single vector of d dimensions]\n",
    "    w : weight vector of dimensionality d\n",
    "    b : bias (scalar)\n",
    "    Output:\n",
    "    preds: predictions (1xn)\n",
    "    \"\"\"\n",
    "    w = w.flatten()\n",
    "    predictions=np.zeros(xs.shape[0])\n",
    "    if b==None:\n",
    "        b=0\n",
    "    for i in range(xs.shape[0]):\n",
    "        if (w.T@xs[i]+b)>=0:\n",
    "            predictions[i]=1\n",
    "        else:\n",
    "            predictions[i]=-1\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(perceptron_classify(x_test,weights,bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9975186104218362\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ',np.sum(classify_linear(x_test,weights,bias)==y_test)/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "Perceptron works perfectly when it is easy to separate the positives from the negatives and all features have equal weight. In some cases normalizing data is necessary in order to prevent one variable having more weight than the rest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
